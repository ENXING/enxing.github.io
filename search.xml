<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[被“辩证法”毒害的中国人]]></title>
    <url>%2F2020%2F%E8%A2%AB%E2%80%9C%E8%BE%A9%E8%AF%81%E6%B3%95%E2%80%9D%E6%AF%92%E5%AE%B3%E7%9A%84%E4%B8%AD%E5%9B%BD%E4%BA%BA.html</url>
    <content type="text"><![CDATA[转载 被“辩证法”毒害的中国人 每年高考结束后，高考作文题都会成为人们解读、议论的焦点。然而人们普遍忽视了高考作文题的最大特点——“辩证”扎堆。今年虽然有所收敛，但“科技的利与弊”、“想着拥有还是想着没有”等辩证题目仍然不少。… 不但高考作文题简直爱死了辩证，在日常生活中，国人也把“你要辩证的看问题”挂在嘴边。当代思想家顾准曾总结说：“中国人是天生的辩证法家”。 可是顾准又说“辩证法把中国人坑害苦了”。这是咋回事？ 【一个无敌句式——你要辩证的看问题】 无论你说啥观点，“辩证的看问题”都能将你轻易击败 有个笑话这样说： 上课时，我放了一个屁——很普通的屁。既不很臭，当然也绝对不香。/可怕的是，教授正在讲辩证法。/“请你自己对这个屁作一下判断，”教授说，“它好还是不好？”/我只得说：“不好。”/“错了，”教授说，“任何事物都由矛盾组成，有它不好的一面，肯定有它好的一面。” 这个笑话看起来很有趣。然而这真的是个笑话吗？君不见： 当我们说民主是个好东西时，总有个故作老成的人充满智力优越感的说：你要辩证的看问题，民主不是万能的，民主有民主的缺陷…… 当我们说强拆是个坏东西时，那个“智者”又跑出来说：你要辩证的看问题，强拆有强拆的作用，不强拆怎么发展…… 当我们批评官员的腐败风气时，“智者”又开口了：你要辩证的看问题，官员也很不容易…… 当我们…… 哦，对了，“你要辩证的看问题”还有个一样无敌的姊妹句式——“你太偏激了”。… 更厉害的是“辩证的看问题”发展到高级阶段后，你连发表观点的必要都没了 在“方舟子打假唐骏”时，一位叫“李国良”的网友说：“方说非黑即白，看来其完全不懂辩证法。这个世界上任何事情都是相对的，黑中有白，白中有黑，方却一口咬定他就是白，唐就是黑，连对立统一规律都不懂。” 你看看，遇到更大的“智慧”，你发现其实说什么观点都是多余的，反正“黑中有白，白中有黑”，进一步“善中有恶，恶中有善”，最后“是中有非，非中有是”，所以“是非”并不分明，甚至有人直接说本就无所谓“是非”，你还废什么话。… 【“辩证法”让我们由不安变得心安】 当我们为假丑恶不安时，一“辩证”就释然了 生活中每天都发生着各种假丑恶，有些假丑恶就发生在我们身边，或者我们就参与其中。如果我们批评或抵触假丑恶，可能会对自己不利；而不批评不抵触，自己内心又不安。 这时候，“辩证法”就派上用场了。只要我们改变思维方式，去“全面的”看待假丑恶，那么你会发现假中有真、丑中有美、恶中有善。唐骏是造假，可人家毕竟激励了很多年轻人；贪污让人痛恨，可贪污也是经济的润滑剂；强拆是惨烈，但没有大拆大建哪来让我们骄傲的市容市貌…… 就这么一“辩证”，我们发现不但原来认为的假丑恶没那么糟糕了，甚至面目可爱起来，简直能成为真善美了。张艺谋不就在《英雄》中通过“辩证”的思维把暴君捧为英雄了吗？所以我们还有什么不能心安理得的。 … 所以“辩证法”是犬儒的最爱 所谓儒，就是知识分子；所谓犬儒，就是像狗一样的奴才知识分子。知识分子本该是道义的坚守者，无奈上面要指鹿为马，知识分子该怎么办？坚持“鹿不是马”，要掉脑袋；而难得糊涂，才能明哲保身。 “辩证法”正是一门“糊涂”学问。被誉为“中国古代辩证法”的老庄哲学，有不少这类说法：“物无非彼，物无非是。”“彼出于是，是亦因彼。”“方可方不可，方不可方可；因是因非，因非因是。”“是亦彼也，彼亦是也。彼亦一是非，此亦一是非，果且有彼是乎哉？果且无彼是乎哉？”“恶乎然？然于然。恶乎不然？不然于不然。……无物不然，无物不可。……恢诡谲怪，道通为一。”（见《庄子·内篇·齐物论》） 在庄子看来，马亦鹿也，鹿亦马也，所谓“万物一齐”也。于是知识分子们释然了：你指鹿为马，我难得糊涂，“不谴是非，以与世俗处”。 … 【中国人信奉的“辩证法”实乃诡辩术与捣糨糊术】 辩证法作为一个哲学概念本无害 尽管辩证法作为一个哲学概念，有丰富的内涵，但公认的辩证法的核心就是对立统一论。 教科书上说，对立统一是指世界上一切事物都包含着两个方面，这两个方面既相互对立，又相互统一。 事实上，这里的“一切事物”指的是“一切连续性的概念”，比如高度、数量、面积、价值。拿高度来说，包含高和矮两个方面，高矮对立，但没有高就无所谓矮，没有矮就无所谓高，而且随着标准的变化，原来高的以后可能变成矮的，反之亦然，这就叫两个方面的统一性。 如果辩证法仅仅是指上述这样的哲学概念，那么无错，更无害。 但被中国人灵活应用后的“辩证法”成了诡辩术 然而中国人理解的“辩证法”，却是抓住“一切”、“两个方面”、“统一性”等字眼大做文章。 比如“唐骏造假了”，这本来是个事实判断，根本不是个“连续性的概念”，不适用辩证法，更不存在“两个方面”的问题。 再比如“唐骏造假的价值如何”，这是个价值判断，对一件事做价值判断必然可以判断出好和坏两个方面，但“唐骏造假的价值如何”同样不是个“连续性的概念”，也不适用于辩证法。唐骏造假的正面价值——激励了年轻人，和负面价值——损害诚信，二者根本是两回事，不存在什么“统一性”。 但是，中国人的“辩证法”却认为，既然“一切事物”都有“两个方面”，那么“唐骏造假了”肯定也有两个方面，然而这两个方面是什么？你总不能说唐骏既造假也没有造假吧？于是“聪明”的中国人继续挖掘，发现做价值判断总是能找到“两个方面”，于是就以价值判断的多样性来混淆事实判断的单一性，在我们指出唐骏造假这个事实时，在旁边一个劲说“唐骏造假的积极意义”。 好吧，既然你要做价值判断，那我们就来谈谈唐骏造假的负面作用。这时候，“聪明”的中国人又拿出了“统一性”法宝，把两个逻辑上不相干的事情“统一”到一个逻辑下，以“唐骏激励了年轻人”来否定“唐骏损害了诚信”，如此“鸡同鸭讲”（实际上这种“鸡同鸭讲”普遍的出现在中国的各种辩论比赛中，这种比赛的题目设置往往就是要求选手们“鸡同鸭讲”）。 好吧，既然你要讲“统一”，那么我们从整体来看，“唐骏损害了诚信”之恶还是超过了“唐骏激励了年轻人”之善吧？所以唐骏造假的整体价值仍是恶的。 这时候“聪明”的中国人又绕了回去——“你不要太偏激了，毕竟人家唐骏激励了年轻人，你自己又有什么贡献……”。 所以中国人的“辩证法”就是种以价值判断混淆事实判断、让逻辑上不相干的价值左右互搏、以局部的价值否定整体的价值的诡辩术。… 更“高级”的“辩证法”干脆认为不存在是非、善恶，一团糨糊就是最大的“智慧” 更“聪明”的中国人都懒得诡辩了，他们认为既然“两个方面”有“统一性”，可以“相互转化”，那么“两个方面”不是“你中有我、我中有你”、“你亦是我、我亦是你”吗？“两个方面”根本就分不清嘛。明白了“分不清”这个“本质”，才是达到了“手中无剑、心中亦无剑”的最高级“智慧”。“聪明难，糊涂更难”啊。… 【结语】 以后再有人故作老成、装出一副“智者”模样说“你要辩证的看问题”，你就拿这个专题砸他的脸。]]></content>
  </entry>
  <entry>
    <title><![CDATA[“中国式辩证法” 错在了哪里]]></title>
    <url>%2F2020%2F%E2%80%9C%E4%B8%AD%E5%9B%BD%E5%BC%8F%E8%BE%A9%E8%AF%81%E6%B3%95%E2%80%9D-%E9%94%99%E5%9C%A8%E4%BA%86%E5%93%AA%E9%87%8C.html</url>
    <content type="text"><![CDATA[转载 “中国式辩证法” 错在了哪里？ 辩证法是好东西，但 “中国式辩证法” 不是。 做了十多年的历史编辑，我时刻感受着 “中国式辩证法” 的无穷威力。 谈商鞅暴政害民，会有人留言来教育： “要辩证地看问题，任何事情都有它的两面性，商鞅变法有残忍的一面，但它让秦变强，统一六国，结束了分裂。” 谈汉武帝执政造成 “天下户口减半”，会有人留言来教育： “要一分为二辩证地看问题。汉朝老百姓是付出了沉重的代价，但打败了匈奴，才有了我们今天作为汉人的荣光。” 谈中医典籍里的 “上吊绳治癫狂、吃白云治哑症” 很荒唐，会有人留言来教育： “中医典籍还是要辩证地去看，不能生搬硬套，去其糟粕，取其精华。” 谈小学、初中文言文数量剧增不妥，会有人留言来教育： “猛增就是牺牲品了？任何事物都有双面性吧！要用辩证的思维去看待这个问题。” 谈不存在 “真气” 这种东西，会有人留言来教育： “真气到底有没有，这个问题是要去探讨的，有时候不是科学的并不是错的，迷信的。现代科学建立在数学基础上，数学不能解释的东西太多了就都是骗人的？？？不能以辩证的思维去想问题是可怕的。” 谈阴阳五行理论不能治病，会有人留言来教育： “任何事物都要辩证的看待啊！这么基本的哲学素养都不会啊！”“要辩证看待事物和问题。一棍子打死，那就是胡说八道了。” 谈政治人物犯下的历史错误，会有人留言来教育： “初中政治课就学过‘事物都具有两面性，要辩证的看问题’，伟人的属性首先也是‘人’。秦始皇一统华夏车同轨书同文，但是也有焚书坑儒；唐玄宗有‘开元盛世’，却也有‘安史之乱’……” 如此种种，都是公号后台的真实留言。 这不能不让人想起那篇广为流传的文章——《辩证法与放屁》。文章的作者虚构了这样一个故事： 上课时，我放了一个屁——很普通的屁。既不很臭，当然也绝对不香。 可怕的是，教授正在讲辩证法。 “请你自己对这个屁作一下判断，” 教授说，“它好还是不好？” 我只得说：“不好。” “错了，” 教授说，“任何事物都由矛盾组成，有它不好的一面，肯定有它好的一面。” “那么说它好也不对了？” 我问。 “当然。” 教授说。 “它既好又不好。” “错了。你只看到矛盾双方对立斗争的一面，没有看到他们统一的一面。” 我只好认真看待这个严肃的问题，仔细想了想说：“这个屁既好又不好，但不好的一面是主要的，处于主导地位。” “错了。你是用静止的观点看问题。矛盾的双方会相互转换，今天处于主导地位一面，明天可能处于次要地位。” “你是说明天全人类会为了我的这个屁欢呼雀跃吗？” “不尽如此，但不能否认这种发展趋势。” 我愣了好大一会儿，只得硬着头皮说：“我的屁既好又不好，既不好又好。今天可能不好，明天一定会好。今天可能很好，明天也许会不好。” 故事很荒诞对不对？ 然而，一旦把故事中的 “上课放屁”，替换成 “商鞅暴政”、“汉武帝户口减半”、“上吊绳治癫狂”、“阴阳五行理论不能治病”、“大政客犯下历史错误”，就鲜少有人觉得荒诞了。 在讨论上述问题的时候，“任何事物都由矛盾组成，有它不好的一面，肯定有它好的一面”、“你只看到矛盾双方对立斗争的一面，没有看到他们统一的一面”、“你是用静止的观点看问题。矛盾的双方会相互转换，今天处于主导地位一面，明天可能处于次要地位”，这些套话，简直可以说是放之四海而皆准、无往而不利的大杀器。 为什么会这样？“中国式辩证法” 究竟错在了哪里？ 邓晓芒教授的《哲学史方法论十四讲》一书中，有一段很精辟的解释： “辩证法讲矛盾，就是自己和自己的矛盾，这是最根本的矛盾，然后发展出了两个对立面。真正的辩证法、西方发展出来的高级辩证法应该是这样的。但是中国的辩证法没有进入这一层次，它总是一开始就给定了一个东西，然后发现它是由两个部分所组成的，这个组成也是给定了的，本来就有，也许你开始看不出来。…… 既然这东西本来就有两个东西，那么你就可以加一个东西进去，所谓‘掺沙子’，把这个对立面掺进去，使它成为一个对立面，这就成为了一种操作的技法、一种技巧。辩证法在中国变成了‘变戏法’，就是因为这一点。它是一个既定的东西，你当然可以人为地改变他，不是那个东西自己要把自己否定，变成另外一个东西，而是由于受到某种外在的干扰，所以它就变成了另外一个东西。我们为了使它成为另外一个东西，可以加入一种外在的干扰，就是掺沙子、丢石头，××× 发明了一系列这样的技法，这就是我们讲的变戏法，就是一种技巧。如何在两个对立面保持平衡，然后由一个第三者去支配、在后面去操纵，这就成为了一种权术。其实自古以来就是这样理解的，老子的辩证法就是一种阴谋权术。”（邓晓芒，《哲学史方法论十四讲》，重庆出版社，2015，第 146~147 页） 就哲学层面而言，这段话其实很通俗了。 我不揣浅陋，再将之稀释一下： 在苏格拉底、柏拉图的时代，“辩证法” 是一种讨论问题的方法，如其字面意思，旨在 “以辩论的方式来证实或者证伪某种观点”，这种辩论以促成彼此理解、达成共识为目的，一般称之为 “古典辩证法”。与之相反的是 “雄辩术”，一种从既定结论出发寻找证据的辩论技巧，以使用各种话术、压倒对方获取胜利为终极目的。 显然，这种 “古典辩证法” 与所谓的“中国古典辩证法”——事物有阴就有阳、事情有好就有坏，完全是两码事。 现代辩证法借鉴了柏拉图时代的 “辩证” 一词，重点关注事物自身的变化。一个典型的例子是 “人不能两次踏进同一条河流”——河流在变化，前一刻的河流与后一刻的河流，在水量、河床宽度、深度等方面，均会出现虽细微但必然存在的变化，后一刻的河流，已非前一刻的河流，二者构成了一堆矛盾，后者取代了前者，构成了对前者的否定。因为后一刻的河流是从前一刻的河流发展而来，所以二者虽然存在取代关系，但又是统一的。这就是所谓的 “自己和自己的矛盾”，对立、统一同时又处在发展之中。 但 “中国式辩证法” 的操作模式完全不同。 中国的 “辩证法专家”，会像将“气” 切割成 “阴”、“阳” 两面一样（即所谓的“阴阳一气”），先把这条河流切成概念相反的两块（比如清、浊），然后说这两块东西，既对立又统一，还处在运动中，可以互相转化。 所以，黑格尔的辩证法（尽管他未曾给辩证法下过明确的定义）是一种认知事物的方法论。“中国式辩证法” 却成了一种愚弄人、捣糨糊的权术。 比如，“塞翁失马，焉知非福”这个典故，迄今仍广泛出现在各种以 “中国式辩证法” 为论述主旨的学术著作之中，这些著作特别喜欢拿这个故事举例，来让读者感受何谓“辩证法”。 其实，这个寓言和真正的辩证法，半毛钱关系也没有。 塞翁丢马（祸）、马带回野马（福）、野马摔断塞翁儿子的腿（祸）、断了腿不用去服兵役送死（福），这根本是四件不同的事（只不过当中同时有 “马” 这个元素）。 真正的辩证法，它关注的是 “自己和自己的矛盾”，是后一刻的河流与前一刻的河流的对立、统一与转化，不是掺入一大堆外部因素（附近有野马、儿子爱骑马、朝廷要打仗）——也就是邓晓芒教授所谓的 “我们为了使它成为另外一个东西，可以加入一种外在的干扰”——然后把四件不同的事，搅和在一起，进而把 “失马” 这件坏事，搅成一锅是非不分的浆糊。 简言之，塞翁丢马（祸）—马带回野马（福）—野马摔断塞翁儿子的腿（祸）—断了腿不用去服兵役送死（福），这四件不同的事之间，不构成任何的辩证法。有的只是各种不可预知的因素对命运造成的不可预知的影响。把这些不可预知的因素造成的不可预知的结果，当成 “辩证法”，当成一种规律，是一种赤裸裸的流氓逻辑。 辩证法的实质，是一种认知事物的方法论。它的核心要义，在于质疑、否定和反思。也就是对既有认知提出挑战，也就是 “辩”，进行认知的回溯，以抵达更深层次的认知，亦即是 “证”。这种回溯，可以视为一种无止境的操作。 比如，当我们指着一棵树、将之称呼为 “XX 树” 时，按照日常生活的既定认知，这棵树就已经确定是 “XX 树” 而并非别的树了。但进入到辩证法的层面，这一既定认知，就会面临很多挑战——我们吃了一顿午饭回来，再指着这棵树，它还是之前那棵 “XX 树” 吗？我们什么也不干一直用手指着这棵树，后一分钟的这棵树，还是前一分钟的那棵 “XX 树” 吗？进而，问题就回溯到了 “何谓树”、“何谓 XX 树” 这个层面。 但 “中国式辩证法” 不是这样操作的。 “中国式辩证法”讲究的是将事物 “一分为二”，认定事物当中本就包含着“对立” 的两个方面，认知者唯一需要的做的，是操起到来，如砍西瓜一般，将事物砍成两半，然后念诵真言——“既有好的一半，也有坏的一半”。 这是典型的 “诡辩术”。 某一具体事物，对某一群体（比如民众）可能有害（或者害大于利），对另一群体（比如皇权）可能有益（或者利大于害），这是常见现象。但这并不意味着该事物可以被 “一分为二”，“既有好的一面，也有坏的一面”。对承受其害者而言，该事物“有害” 的性质是确定的；对承受其利者而言，该事物 “有益” 的性质也是确定的。将这种可以确定的性质，模糊成“既有好的一面，也有坏的一面”，结果便只有是非的丧失。 具体到 “商鞅暴政害民”、“汉武帝户口减半”、“上吊绳治癫狂很荒唐”、“阴阳五行理论不能治病”…… 这些结论本身都是可以确定的——纵然不认可，也不过是对结论的真伪进行再商榷，而非结论本身可以 “一分为二”，“既有好的一面，也有坏的一面”。 面对这些结论，呼喊着 “要辩证地看问题” 者，浑然忘了如果自己活在商鞅、汉武时代，被信奉阴阳阴阳五行的传统医师诊断，多半会成为 “户口减半” 中的一份子。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Numeric-hw05]]></title>
    <url>%2F2018%2FNumeric-hw05.html</url>
    <content type="text"><![CDATA[Problem 1 [P301_6.2]Solution: $f(x) =x^2$ Strictly Convex. $f(x) =x^3$ NonConvex. $f(x) =e^{-1}$ Strictly Convex. $f(x) =|x|$ Convex not Strictly Convex. Problem 2 [P301_6.3]Solution: $H_f =2$, minimum on R; $H_f =6x|_{x=0} = 0$, not minimum on R $H_f = 12x^2 \geq 0$, minimum on R $H_f = 12x^2 \leq 0$, Maximum on R Problem 3 [P301_6.7]Solution: $L = f(x) + \lambda g(x)$ $\nabla L = \begin{bmatrix}2x_1 -2 +\lambda \\2x_2 - \lambda \\ -2x_3+4 + 2\lambda \\ g(x)\end{bmatrix}$ $B = H_f + \Sigma \lambda H_{g_i}= \begin{bmatrix} 2&amp;0&amp;0\\ 0&amp;2&amp;0\\0&amp;0&amp;-2\end{bmatrix}$ $J_g = \begin{bmatrix} 1\\ -1 \\ 2\end{bmatrix}$, $J_g^\perp = \begin{bmatrix}-1 &amp; 1\\ 1 &amp; 1 \\ 1 &amp;0\end{bmatrix}$ ${J_g^\perp}’ B J_g^\perp = \begin{bmatrix}2 &amp; 0\\ 0 &amp;2\end{bmatrix}$ is positive efinite Matrix. So $x^*$ is constrained minimum. Problem 4 [P301_6.9]Solution: $f(x ) =\frac{1}{2} x’Ax - x’b +c$, $\nabla f = Ax -b$, $H_f = \nabla^2 f = A$, $x_1 = x_0 +s$, $s = H_f^{-1} (-\nabla f)|_{x = x_0}$, $x_1= x_0 -A^{-1} (Ax_0-b) = A^{-1}b$. When $\nabla f = 0$ (equivalently $x = A^{-1}b$) this function is minimized.So for any starting point $x_0$ , Newton’s method for minimizing this function converges in one iteration. If $x_0 - x^$ is an eigenvector of A, the steepest descent method for minimizing this function converges in one iteration. $\nabla f(x_0) = Ax_0 - b$, $Ax^ -b = 0$, subtraction of two equations. $A(x_0 - x^) = \nabla f(x_0) = \lambda (x_0 -x^)$.Matrix A is a definite matrix, $\lambda &gt;0$. Next iteration $x_1 = x_0 - \nabla f(x_0) \cdot \alpha = x_0 - \lambda(x_0 -x^ )\alpha = (1-\lambda \alpha)x_0 + \lambda \alpha x^$. Let search step $\alpha = \lambda^{-1}$, then $x_1 = x^*$. Problem 5 [P302_6.12]Solution: If there is another point $y \in S , \ (y\neq x)$ such that $f(y) &lt; f(x)$, $f(\lambda y + (1-\lambda) x ) \leq \lambda f(y) + (1-\lambda)f(x) 0$ such that for any z: $|z - x| &lt; \delta$, $f(x)\leq f(z)$. To find $\lambda$ such that $|\lambda y + (1-\lambda) x -x| = |\lambda (y-x)| &lt; \delta$, Choose $\lambda _0= \frac{\delta}{2|y-x|}$ and denote $\hat{x} = \lambda _0 y + (1-\lambda _0)x$. Then we have $f(x) \leq f(\hat{x})$, and $|\hat{x_0} -x| &lt; \delta$ . But we have $f(\hat{x}) &lt; f(x)$. Contradiction.So $f(x)$ is a global minimum of $f$ on $S$. If there is another point $y\in S$ and $y\neq x$ such that $f(y) = f(x)$ achieving a global minimum.As $f$ is strictly convex function $f$, $f(\lambda y + (1-\lambda) x ) &lt; \lambda f(y) + (1-\lambda)f(x)= f(x)$ , for any $\lambda \in [0,1]$ . Contradiction. There is a unique global minimum of $f$. Problem 6For a sparse positive definite matrix $A$, if you have a way to find a sparse lower triangle matrix $L$ so that $L’AL$ has a much smaller condition number than $A$, how would you solve the linear equation $Ax=b$ with Conjugate Gradient method? Solution: Perhaps you can choose transformation of $x = Ly, \ L’b = bb$ , and then linear equation $Ax = b$ becomes $L’ALy = bb$. Denote $L’ AL = \hat{A}$. Original equation becomes $\hat{A} y= bb$, where $\hat{A} $ has much a smaller condition, which can improve computation accuracy. And impose Conjugate Gradient method. Problem 7Source Code Download Computer problem (in C or C++): Write the functions to achieve (1) CG method with a linear search method; (2) CG method for linear systems with positive definite matrix. Test these algorithms for a few matrix and check the orthogonal properties for the residuals for a large scale linear system. Solution: CG method with a linear search method; minimize test function :$f = \frac{1}{2} x^T A x - b^Tx$.Linear search is through Secant Method. CG method for Linear systems with psd matrix. data.txt Problem 8Source Code DownloadComputer problem (in C or C++): Achieve the interpolants of Runge’s function at equally spaced points. Solution: number of partition $n = 10$ number of partition $n = 18$ number of partition $n = 20$ Link, this Link you will see all cases and can help readers understand visually the phenomenon of Runge. Problem 9Computer problem (in C or C++): Write the functions to find the natural cubic spline function using the shooting method and the B-spline method. Solution: Shooting Method — Source Code Download number of partition $n = 2$ number of partition $n = 5$ number of partition $n = 7$ number of partition $n = 9$ number of partition $n = 10$ number of partition $n = 12$ number of partition $n = 15$ B-Spline method Still in process Idea B-Spline reference]]></content>
      <categories>
        <category>Numeric</category>
      </categories>
      <tags>
        <tag>2018-fall</tag>
        <tag>numeric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numeric-hw04]]></title>
    <url>%2F2018%2FNumeric-hw04.html</url>
    <content type="text"><![CDATA[Problem 1 [P208_4.13]Solution: for any eigenvalue $\lambda$ of matrix A , there exists a corresponding eigenvector:$X \neq \bf{0}$ and $AX=\lambda X$ And we have $||A|| \cdot ||X||\geq||AX|| = ||\lambda X|| = |\lambda| ||X||$ , then$|\lambda| \leq ||A||$ and $\rho(A) = {max}_{\lambda_i}\{|\lambda_i| \} \leq ||A||$ Problem 2 [P209_4.19]Solution: $A^2 - A = 0; A^2 X - A X = 0; \lambda ^2 - \lambda = 0;$so we have $\lambda = 0 , 1$ Problem 3 [P209_4.20]Solution: a Hermitian matrix (or self-adjoint matrix) is a complex square matrix that is equal to its own conjugate transpose. notice that eigenvalue of Hermitian matrix is real number. a) $\begin{align}&amp;\lambda = &lt;\lambda x, y&gt; = = \\ &amp;= = = \mu \end{align}$ ,and$\lambda \neq \mu$. So we get $y^Hx =0$ b) $\begin{align}&amp;\mu^H = = = \\ &amp; = &lt;\lambda x, y&gt;= \lambda^H \end{align}$. And $\lambda \neq \mu$, then $y^Hx =0$ c) give a counterexample: $A = \begin{bmatrix} 1 &amp; 2 \\ 0 &amp; 2\end{bmatrix}$, for $\lambda = 1$, its eigenvector: $x = [1, 0 ]^T,$ and $y = [0.4472, -0.8944]$, obviously we find $y^Hx\neq0$ Problem 4 [P209_4.24]Solution: a) As $A$ is a real matrix of rank one, we know it must have non zero row $r_i$ that can linearly represent all the other row $r_j;j≠i$.So we get$\begin{align}A&amp;=[ a_ 1 r_ i,a_2r_i,\cdots,a_ {i-1} r_ i, r_ i, a_ {i+1} r_ i , \cdots ,a_ n r_ i]^T \\\ &amp;=[a_1 , a_2 ,\cdots , a_ {i-1} ,1 , a_ {i+1} ,\cdots ,a_n ]^T \cdot r_ i = u \cdot v^T\end{align}$,and $v = r_i^T\ ;\ u =[a_1 , a_2 ,\cdot , a_{i-1} ,1, a_{i+1} ,\cdot ,a_n ]^T$ b) $uv^Tu = u\cdot v^Tu = v^Tu u$, so we get eigenvalue $v^Tu$ and corresponding eigenvector $u$ c) As $A$ is a matrix of rank one, we know have $n−1$eigenvalue equal to zero, and the rest one is $v^Tu$. d) Only one step.Let $x = \Sigma_{i=2}^n \alpha_i v_i + \alpha u$, then $Ax = 0 + \alpha u^Tv u = C * u$. Problem 5 [P210_4.25]Solution: As matrix of rank one has a property of Algebraic multiplicity equal to Geometric multiplicity, we know there exists an inverse matrix $P$,such that $uv^T = P^{-1} diag [v^Tu, 0 , 0 , 0, \cdots ,0 ] P$ . So we have $det(I + uv^T) = det(I + diag[v^Tu, 0 , 0 , 0, \cdots ,0 ]) = 1 + u^Tv$ Problem 6 [P210_4.27]Solution: Matrix $A$ is similar to Jordan matrix $J$, So there is a inverse matrix $P$ such that $P^{−1}AP=J$.The $|I-A| = |I- J| = \prod_{i = 1}^{n}(1-J_{ii}) &gt; (1-\rho(A))^n \neq 0$. $(I- A) \cdot \Sigma_{k = 0}^{\infty}A^k = I$ Problem 7 [P210_4.31]Solution: a) $||Qx||_2 = ||\lambda x||_2= |\lambda|\cdot ||x||_2$. Also we have $||Qx||_2 =\sqrt{(Qx)^TQx} =||x||_2$ and we know eigenvector $x\neq = 0$. So $|\lambda| =1$. b) $Q = Q\cdot I \cdot I$, So singular values of an orthogonal matrix is 1. Problem 8 [P210_4.32]Solution: a) we have $Hv = -v, Hv^{\perp} = v^\perp$, so we know eigenvalues of the Householder transformation is $[-1, 1, 1,\cdots , 1]$. ($n-1$ multiplicities of eigenvalue $1$). b) $e^{-i\theta}, e^{i\theta}$, where $c = cos(\theta),s = sin(\theta)$. Problem 9if pivot should be used in the QR decomposition, how would you do in the QR iteration? Solution: $A_0 = A$ for $k = 1, 2, ..$ Calculate QR Factorization with pivot $A_{k-1}P_k = Q_kR_k$ ($A_{k-1} = Q_kR_k P_k^{-1} =Q_kR_k P_k$) $A_{k} = P_kR_kQ_k$ end Problem 10If a Martix is large and sparse, how would you find its largest 10 eigenvalues and eigenvectors? Solution: Use Householder transform or Arnoldi Iteration to let sparse matrix be Hessenberg matrix, and use Orthogonal Iteration with $X_0$, a rank-full matrix with n rows and 10 columns. Problem 11Source Code Download Computer Problem (in C or C++): Write the functions to achieve (1) Arnoldi iteration and Lanczos iteration; (2) QR iteration for Hessenburg matrix to find the eigenvalue decomposition. Test these algorithms for a few matrix. Solution: Lanczos iteration is one of special cases of Arnoldi iteration,so only the complex one–Arnoldi iteration is programmed.I consider the situation that matrix is reducible and solve it. You can input any square matrix. Here is a test case. reducible Matrix: extreme special Matrix: QR iteration (the following photos are testing case!) Up-Hessenberge Matrix: Rank One Matrix: Matrix with Complex Eigenvalue (from Sub-square matrix 2*2 in row = 2, column = 2): Symmetry Dominant Diagonal Matrix: Problem 12 [P248_5.5]Solution: $\begin{split} x_{k+1} &amp;=\frac{x_{k-1} f(x_k) -x_k f(x_{k-1})}{f(x_k) - f(x_{k-1})} \\&amp;= \frac{x_{k-1} f(x_k) -x_k (f(x_{k-1}) -f(x_k)) - x_kf(x_k)}{f(x_k) -f(x_{k-1})} \\&amp;=x_k - \frac{f(x_k)}{ \frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}} } \end{split}$ formula given in part a) is better than the formula for the secant method given in Section 5.5.4. the secant method will lose accuracy. Problem 13 [P250_5.10]Solution: root = 1.307; $2x \cdot cot(x) - (x^2 -1) = 0$ this zero must be bigger than 0; Problem 14Source Code Download Computer Problem (in C or C++): Write the functions to achieve Newton’s method and Broyden’s method. Test these methods for a few equation systems. Solution: Equation System Solved by Newton’s Method: $f(x) = \begin{bmatrix} x_1 + 2_2 -2\\ x_1^2 +4x_2^2 -4\end{bmatrix} = \begin{bmatrix} 0\\ 0\end{bmatrix}$$J_f(x) = \begin{bmatrix} 1&amp;2\\ 2x_1 &amp;8x_2\end{bmatrix}$ Equation System Solved by Broyden’s Method: data.txt Compare two method’s iteration numbers when achieving the same accuracy.Iteration number of Newton’s method is 7, and Broyden’s method is 16. Newton’s methods is more faster to converge, however Jacobi Matrix is needed to be compute explicitly in advance .]]></content>
      <categories>
        <category>Numeric</category>
      </categories>
      <tags>
        <tag>2018-fall</tag>
        <tag>numeric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[encryption]]></title>
    <url>%2F2018%2Fencryption.html</url>
    <content type="text"><![CDATA[problem 1 [ Page 148, 3.30] Solution As the normal vector is: $v = \bf{a} - \alpha \bf{e_1}$, we need avoid cancellation. So the sign should be : \bf{-}sign(\bf{a}^T \cdot \bf{e_1})]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VIM_NOTE]]></title>
    <url>%2F2018%2FVIM-NOTE.html</url>
    <content type="text"><![CDATA[MARK1.设置标签ma 在当前位置设立一个标签名字是a，这是一个局部标签，只在当前文件内有效。如果要设置全局标签，在多个文件之间跳转的话，只要将标签名字大写就可，即mA。2.标签跳转`a 跳转到标签a的位置3.标签删除 delmarks a4.查看当前设置的标签 ：marks]]></content>
      <categories>
        <category>NOTE</category>
      </categories>
      <tags>
        <tag>NOTE</tag>
        <tag>VIM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numeric-hw03]]></title>
    <url>%2F2018%2FNumeric-hw03.html</url>
    <content type="text"><![CDATA[problem 1 [ Page 148, 3.30]Solution: As the normal vector is: $v = \bf{a} - \alpha \bf{e_1}$, we need avoid cancellation. So the sign should be : \bf{-}sign(\bf{a}^T \cdot \bf{e_1}) problem 2 [ Page 148, 3.33]Solution: (Reference) LU factorization Of A: if no using partial pivoting, No additional storage of memory is needed except storage of matrix A. if using partial pivoting, the permutation matrix P need to be stored, and only need an extra storage of $(n - 1) \times 2$ array. QR factorization of A: only need an extra storage of $m \times 1$ array. Following Graph: problem 3 [ Page 149, 3.44]Solution: Matrix elementary transformation. find max integer r, such that there is a sub-square-matrix formed by entries intersected by r rows and r columns of rectangular matrix and that determinant is no equal to zero. QR-Householder decomposition, observe matrix R, can easily get rank. Singluar Value Decomposition, observe non-zero of diagonal matrix. problem 4 [ Page 149, 3.45]Solution: $(c) &gt; (a) &gt; (b)$ problem 5 [ Page 149, 3.1 ]Solution: $\begin{bmatrix}1 &amp; 10 \\\ 1 &amp; 15 \\\ 1&amp; 20 \end{bmatrix} \begin{bmatrix}x_1\\\ x_2\end{bmatrix}=\begin{bmatrix}11.60\\\ 11.85\\\ 12.25 \end{bmatrix}$ inconstitent. $x_1 = 11.10 ,\ x_2 = 0.05 (eqn \ 1 \ and \ 2)$ $x_1 = 10.65,\ x_2 = 0.08 (eqn \ 2 \ and \ 3)$ There is no reason to prefer any one of these result. normal equation: $A = \begin{bmatrix}1 &amp; 10 \\\ 1 &amp; 15 \\\ 1&amp; 20 \end{bmatrix}$ ; $b= \begin{bmatrix}11.60\\\ 11.85\\\ 12.25 \end{bmatrix}$ $A^{T} \cdot A x = A^T b$ $x_1 = 10.9250, \ x_2 = 0.0650$ the result got by normal equation is better than those obtain in part b, and that seems to be certain average of possible pair of values obtained by selecting any two of the equation from the system. problem 6 [ Page 149, 3.3 ]Solution: $\begin{bmatrix}1 &amp; e \\\ 2 &amp; e^2 \\\ 3 &amp; e^3 \end{bmatrix} \begin{bmatrix}x_1 \\\ x_2\end{bmatrix}=\begin{bmatrix}2 \\\ 3\\\ 5 \end{bmatrix}$ $A = \begin{bmatrix}1 &amp; e \\\ 2 &amp; e^2 \\\ 3 &amp; e^3 \end{bmatrix} \ and \ b = \begin{bmatrix}2\\\ 3\\\ 5 \end{bmatrix}$ normal equation: $A^{T} \cdot A x = A^T b$ $(x_1,\ x_2) = ( 1.5942, \ 0.0088)$ problem 7 [ Page 150, 3.14 ]Solution: orthogonal : $H^T* H = I$ $H^T*H = (I - 2\frac{vv^T}{v^Tv})^T\cdot (I - 2\frac{vv^T}{v^Tv})$ $=I - 2 \frac{vv^T}{v^T v} - 2 [\frac{vv^T}{v^T v}]^T +4 [\frac{vv^T}{v^T v}]^T * [\frac{vv^T}{v^T v}] = I$ symmetric: $H^T = H$ ; Obviously. problem 8 [ Page 152, 3.31 ]Solution: (Reference) $A^T A X= A^Tb$ $\Rightarrow X = (A^TA)^{-1} A^T b; \ A = U\Sigma V^T$ $\Rightarrow X = ( [U\Sigma V^T]^TU\Sigma V^T)^{-1} [U\Sigma V^T]^T b$ $\Rightarrow X = ( V\Sigma^T\Sigma V^T)^{-1} V\Sigma^T U^T b$ $\Rightarrow X = V\Sigma^{-1}(\Sigma^T)^{-1} V^{-1} V\Sigma^T U^T b$ $\Rightarrow X = V\Sigma^{-1}(\Sigma^T)^{-1} \Sigma^T U^T b$ $\Rightarrow X = V\Sigma^{-1} U^T b$ $\Rightarrow X = V\Sigma^{+} U^T b$ $U = [u_1 , u_2, \cdots , u_n]; V=[v_1, v_2, \cdots, u_n]; $ $\Sigma^{+} = diag[1/\sigma_1 , 1/\sigma_2, \cdots, 1/\sigma_r, 0 ,0 ]$ So we get $X = \sum_{\sigma_i \neq 0} \frac{u_i^Tb}{\sigma_i}v_i$ problem 9 [ Page 152, 3.32 ]Solution: $AA^+A = U\Sigma V^T \cdot V\Sigma ^+U^T\cdot U\Sigma V^T = U\Sigma V^T= A$ $A^+AA^+ =V\Sigma ^+U^T\cdot U\Sigma V^T \cdot V\Sigma ^+U^T =V\Sigma ^+U^T= A^+$ $(A^+A)^T= A^+A$ $(A^+A)^T =(V\Sigma ^+U^T\cdot U\Sigma V^T )^T=V{ \Sigma ^T \Sigma ^+}^T V^T$ $A^+A =V\Sigma ^+U^T \cdot U\Sigma V^T=V\Sigma ^+\Sigma V^T$ Obviously $\Sigma^+\Sigma = (\Sigma^+\Sigma)^T$ $(AA^+)^T= AA^+$ for the same reason, can be proved. problem 10Computer problem (in C or C++): Using Householder transform to achieve the QR decomposition with and without a column pivoting. Then, using QR decomposition to finish 3.8 on page 154. Code Download Cholesky factorization is more sensitive, I think. QR method comes closer to recovering the x that we used to generate the data! Not affect. As it exists the random error, having different solutions is not weird, and we can average the solutions generate by QR method.]]></content>
      <categories>
        <category>Numeric</category>
      </categories>
      <tags>
        <tag>2018-fall</tag>
        <tag>numeric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numeric-hw02]]></title>
    <url>%2F2018%2FNumeric-hw02.html</url>
    <content type="text"><![CDATA[本次作业的源码下载链接 Problem 1 [Page94, 2.45]Solution: 不能直接求矩阵$A$的逆矩阵，否则计算量太大了。设$A^{-1}Bc = x$,则有$Ax=Bc$，那么右端一个矩阵乘以一个向量，计算量很小，然后求解线性方程$Ax=b, b= Bc$，可以用LU 分解等等。 problem 2 [Page 95, 2.48]Solution: $A^{T} = U^{T} L^{T}$ , $U^{T}$是下三角，而$L^{T}$是上三角，因此只考虑$A=LU, Ax=b$： 如果$A$矩阵已经分解成三角形式$A=LU$，那么可以通过两步过程求解出$x$，首先，设$y=Ux$，然后对$y$解方程组$Ly=b$。因为$L$是三角形的，从这个方程确定$y$仅需要$O(n^2)$运算。一旦$y$已知，上三角方程组$Ux=y$仅需要另外的$O(n^2)$运算来确定解$x$。 problem 3 [Page 95, 2.49]Solution: （a）下三角矩阵$Ly=b$只需要$O(n^2 )$计算量，然后置换矩阵$Px =y$只需进行 行交换 可得单位阵而得到求解。 （b）$PLx = b$，这个先对$Py =b$,进行行交换将左端矩阵变成单位阵即可求解，然后 $Lx=y$进行高斯消元只需$O(n^2)$计算量。 problem 4 [Page 95, 2.51]Solution: 可能，如 $x = (4, 4), y=(5, 1)$。 problem 5 [Page 95, 2.52]Solution: $|A|_1$: 是各列1范数的最大值，这个更加容易计算。 problem 6 [page95, 2.57]Solution: A=$\begin{bmatrix}4 &amp; 0 &amp; 0\\\ 0 &amp; -6 &amp; 0 \\\ 0&amp; 0&amp;2 \end{bmatrix}$ $cond(A) = |A|_1 \cdot |A^{-1}|_1 = 6 * 0.5 = 3$ $cond(A) = |A|_ {\infty} \cdot |A^{-1}|_ {\infty} = 6 * 0.5 = 3$ problem 7 [Page 95, 2.61]Solution: a) $cond(A) = 10^ {10} * 10^ {10} = 10^ {20}$ b) $cond(A) = 10^{10} * 10^{-10} = 1$ c) $cond(A) = 10^{-10} * 10^{10} = 1$ d) $cond(A) = 6 * \infty = \infty$ problem 8 [Page 96, 2.77]Solution: $\begin{bmatrix} 4 &amp; 2\\\ 2&amp;2\end{bmatrix} =\begin{bmatrix} 2 &amp; 0\\\ 1&amp;1\end{bmatrix} \cdot \begin{bmatrix} 2 &amp; 1\\\ 0&amp;1\end{bmatrix}$ problem 9 [Page 97, 2.10]Solution: A permutation matrix is a matrix obtained by permuting the rows of an identity matrix according to some permutation of the numbers 1 to . Every row and column therefore contains precisely a single 1 with 0s everywhere else, and every permutation corresponds to a unique permutation matrix. 显然任意行交换矩阵 可以表示成多个单一行交换矩阵连乘: $P = P_1 P_2 P_3 \cdots P_k， P_i^T = P_i, P_i^ {-1} = P_i$ 那么有 $P^T= P_k^T P_ {k-1}^T P_ {k-2}^T \cdots P_k^T = P_k P_ {k-1} P_{k-2} \cdots P_1$ $P * P^T = P_1 P_2 P_3 \cdots P_k \cdot P_k P_ {k-1} P_{k-2} \cdots P_1 = I$ (另一种证明) $P = (e_ {i_1}, e_ {i_2}, e_ {i_3} \cdots e_ {i_n}), P^T = (e_ {i_1}^T, e_ {i_2}^T, e_ {i_3}^T \cdots e_ {i_n}^T)^T$ 显然： $P*P^T= I$ problem 10 [Page 98, 2.31]Solution: 1) $||x||&gt;0$ if $x \neq 0$2) $||\gamma x|| = |\gamma | \cdot ||x||$3) $||x+y|| \leq ||x|| + ||y||$ 第一条更加正定矩阵的定义显然成立。 $||\gamma x|| =((\gamma x) ^T A \gamma x)^ {\frac{1}{2}} = |\gamma| ||x||$ 第二条成立。 \begin{equation}||x+y|| \leq ||x|| + ||y|| \Leftrightarrow [(x+y)^{T} A (x+y)]^{\frac{1}{2}} \leq (x^{T} A x)^{\frac{1}{2}} + (y^{T} A y)^{\frac{1}{2}} \ \ (1)\end{equation} 由于矩阵$A$ 是对称矩阵，那么存在正交矩阵$U$，使得$A = U^T D U$，由于$A$正定 因而有$D$是对角元恒正的对角矩阵，并且$D = d^T d, d_{ii}^2 = D_{ii}, \ d_{ii} &gt; 0;\ d_{ij} = 0 ,\ if: i \neq j$。令$\hat{x} = dU x; \ \hat{y} = dU y$， 则由(1)有 $[(\hat{x} + \hat{y})^T \cdot (\hat{x} + \hat{y})]^{\frac{1}{2}} \leq [\hat{x}^T \cdot \hat{x}]^{\frac{1}{2}} + [\hat{y}^T \cdot \hat{y} ]^{\frac{1}{2}}\Leftrightarrow ||x+y||_2 \leq ||x||_2 + ||y|_2|$，显然成立！ problem 11Computer problem (in C or C++): Using Gaussian elimination to achieve the LU decomposition with and without a column pivoting; Using the two LU decomposition algorithm to solve linear systems in which the coefficient matrix is (1) general nonsingular matrix; (2) positive definite matrix; (3) diagonally dominant matrix. Compare the numerical accuracy for the two algorithms. The size of the matrices should be greater than 1000. code download nonsingular matrix : 选偏主元与否会影响精度，如下图：（选主元的误差会比不选主元的误差小三倍左右） Diagonally dominant matrix: 选偏主元与否不影响精度。]]></content>
      <categories>
        <category>Numeric</category>
      </categories>
      <tags>
        <tag>2018-fall</tag>
        <tag>numeric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numeric-hw01]]></title>
    <url>%2F2018%2FNumeric-hw01.html</url>
    <content type="text"><![CDATA[本次作业的源码下载链接 Problem 1 [Page 45 1.7]Solution: 中心差分 可以看出当$k=10^{-8}$ 达到误差最小，是由于其与分子的双精度误差的开方可比拟的缘故。 和例子1.3 很契合。 向前差分 可以看出当$k=10^{-6}$ 达到误差最小，并不和$h \approx \sqrt{\epsilon_{mach}}$ 一致。 Problem 2 [Page 46 1.9]Solution: 应该取相对误差而不是绝对误差。(b)通过计算: $\frac{x^n}{n!}$ 小于 计算机双精度$10^{-16}$作为计算停止准则。 (c)计算结果如下： (d) 对于负数，由于级数相邻两项符号不一致，而且大小在一个数量级上，相减会丢失精度。所以对负数情况可以求对应的正数再取倒数，测试结果如下: (e) 对负数情况进行分组求和，如将正的放在一起和负的放在一起，最后相减(数值结果如下图)，等操作无法改善精度， 归根究底就是两个想近数相减引起的。因此可以下结论，交换重组项无法改善精度。 e^{-x} = (\frac{x^{0}}{0!} +\frac{x^{2}}{2!}+ \frac{x^{4}}{4!} +\cdots ) -(\frac{x^{1}}{1!} +\frac{x^{3}}{3!}+ \frac{x^{5}}{5!} +\cdots ) Problem 3 [Page 46 1.9](Matlab test) For $n=500, 1000,2000, 4000, 8000$, generate an $n\times n$ random matrix B, and an $n\times 1$ vector b. Find the symmetric matrix $A=B^{\tau} \cdot B$1) Using function “eig” to test the time cost for eigen decomposition;2) Using $x=A / b$, and $x=A^{-1}\cdot b$ to test the time cost in finding the solution of $Ax=b$;3) Plot all the time costs as a function of n and the power law for the time costs. Solution: 1) 计算结果如下： 计算时间耗时： 2) 计算结果如下：$t_1$是没有求逆矩阵求解线性方程所用时间。$t_2$是有求逆矩阵求解线性方程所用时间。不同分量对应不同的维数的矩阵求解时间。 3) 如下图：蓝线是有求逆矩阵的维数对时间的 $log$ 曲线。红线是没有求逆矩阵的维数对时间的 $log$ 曲线。]]></content>
      <categories>
        <category>Numeric</category>
      </categories>
      <tags>
        <tag>2018-fall</tag>
        <tag>numeric</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[transport03]]></title>
    <url>%2F2018%2Ftransport03.html</url>
    <content type="text"><![CDATA[Boltzmann equationf(t, \vec{x}, \vec{u}) \leftarrow evolution the number of moecules in a $d^3\vec{x}$ volume element and $d^3u\vec{u}$ velecity element compact cas-kinetic scheme(gks) 一个有希望的方向compact 4-rd order GKS]]></content>
  </entry>
  <entry>
    <title><![CDATA[transport01]]></title>
    <url>%2F2018%2Ftransport01.html</url>
    <content type="text"><![CDATA[Book: 输运理论 黄祖洽 multiscale Transport modeling &amp; computationgas dynamics: navier-stokes equation : $k_n = \frac{l}{L}$ flud element hydrodyamic （宏观） boltzmam equation “particle” mean free path kinetic scale （介观） radiative transfer (optical thick) 光子和物质相互作用 optical thick diffusion plasma -vlasov eqn 无碰撞 + maxwell + two phase flow magnetic-hydrodynamics two fluid model hall MHD ~ ~ ~ idea magnetic-hydrodynamics different level of description microscopic （微观）( resolution to particle ) Hamiltonian - Newton’s Law indiviual paritcle P_r = -\frac{\partial H}{\partial q_r}q_r = - \frac{\partial H}{\partial p_r}, r = 1,2,...3NH = \sum_{1}^{N} kinetic + potential mesoscopic （介观） (不能跟踪每个粒子 ) mean free path 空间自由程$l_1$ collustion time $\tau_1$ botzmann eqn &amp; distribution function $\rho(x,t,u)$ 7-dim 微观 推导 介观 （BBGKY) 无法给出中间尺度 macroscopic (宏观) Navier-stoks MHD two phase flow multiphase flow \rho , V, T (x, t): 4-dimNewtone -&gt; boltzmann -&gt; NSsingle particle .. 尺度逐渐变大Boltzmann -&gt; NS chapmann enskog expansion burelt supris~ moments – Grad 13, 26, 35 距方程 中间尺度 (非平衡物理 unexplore)： “shock Structure”可能的理论 Difficulties degree of freedom NS (5 degree) conservation law $\rho , \rho v,\rho E$ Boltzmann($\infty$ degree) 不是守恒量的确定方程 自然界没有: \frac{\partial T_x}{\partial t} + ......\frac{\partial T_{xy}}{\partial t} + ......Discontinuous Galerkin “DG” 网格有更多自由度提高精度 (相当于对原控制方程求) \frac{\partial}{\partial x} : \rho _x + (\rho u)_x =0 compact high-order 不是直接建模不可能成功 从Boltzmann 方程直接推出中间尺度 ，难成功 Bolzmann 两体碰撞 trasnsport &amp; collision decouple $\delta t \leq \tau, \delta x \leq l$ 前提 如果$\Delta x \approx 5l, \Delta t \approx 5\tau$ ，未知领域 Numericall metheds macro NS MHD multiphase Numerical PDE Boltzmann DVM SN vlasov particle methods Direct simulation monte carlo (DSMC, bird 1960) 稀波流 稀薄气体 IMC PIC $\Delta x\sim \frac{l}{3}, \Delta t \sim \frac{\tau}{3} , 64nm$ 计算量巨大 multiscale modeling Scale $(\Delta x,\Delta t)$ discrete governing eqn computation (多尺度) $m=10$,飞机头部密度非常大，飞机尾部几乎真空。 空天飞机，网格机头部分粒子很多NS eqn，尾翼粒子稀薄Boltzmann eqn 卫星喷管，箱内密度很高NS方程，喷嘴外真空。 Contents NS eqn continuum mechanics 连续介质流体 用微积分 离散更有优势。 两个粒子黏在一块。 流体微团没有物质交换 Boltzmann Eqn Unified gas Kinetic Scheme rarefied gas raiation Newton transport plasma two phase Particle Version 化学反应 Navier-Stokes Equation : flud gas Navier-Stokes Equation : flud gas$\rho = \frac{\Delta m}{\Delta v}$ kinematic properties: Velocity acceleration vorticity transport properties: viscosity , thermal conductivity Thermodynamic properties: pressure, density temperature location: $X(t),Q(X(t),t)$ $\frac{dQ}{dt} = \frac{\partial Q}{\partial t} + \frac{\partial Q}{\partial X}\frac{\partial X}{\partial t} +\frac{\partial Q}{\partial Y}\frac{\partial Y}{\partial t} + \frac{\partial Q}{\partial Z}*\frac{\partial Z}{\partial t}$ $= \frac{\partial Q}{\partial t} +V \cdot \nabla Q$ \frac{DQ}{Dt} = \frac{dQ}{t} = \frac{\partial Q}{\partial t} + \vec{V} \cdot \nabla Q\vec{V} \cdot \nabla \vec{V} = \nabla \frac{\vec{V}^2}{2} - \vec{V} \times (\nabla \times \vec{V}) \vec{w} = \nabla \times \vec{V}Vorticity: \frac{DV_i}{Dt} = \frac{\partial V_i}{\partial t} + V_j \partial V_i translation (3-degree) rotation (3-degree) extensional strain(3-degree) shear strain(3-degree) Scale Vector second order tensor \nabla V = 0.5 (\nabla V + (\nabla V)^T)_ (shear Strain) + 0.5 (\nabla V - (\nabla V)^T)_ (rotation)反对称张量只有三个自由度 对称张量有六个自由度 $\epsilon_{ij} = 0.5(\partial_j V_i + \partial_i V_j)$ 应变 stress：$\tau_{ij} = f(\epsilon_{ij})$应力 Newton fluid $\tau_{ij} \sim \epsilon_{ij}$ Non Newton fluid $F \sim \alpha \frac{dV}{dy}$ 满足此式是牛顿流体 $\tau_{\alpha \beta}e_{\alpha}e_{\beta}$ $\alpha$ direction of normal $\alpha$ direction of force $f = n \cdot \tau = f_n + f_t$ $f_n = (n \cdot f)$ $f_n = (n \cdot f) n = n \cdot (n \cdot \tau) n = (n n : \tau) n$ $f_t = f - f_n = n \cdot \tau - (nn: \tau) n = f \cdot (I - n n)$ $\tau \sim (\nabla V + (\nabla V)^{T})$ Symmetric tensor $moment = I\frac{dW}{dt} -&gt; 0$ 力矩 $\int\int (r \times f) ds = I \frac{dw}{dt}$ $f = n\cdot \tau$ 流体微团趋于零：$\tau_{ij} = \tau_{ji}$ \tau_{ij} = -P \delta_{ij} (hyrostatic Pressure) + \mu[\frac{\partial V_i}{\partial x_j}+\frac{\partial V_i}{\partial x_j} - \frac{2}{3} \nabla \cdot \vec{V}]Equation of compressible Viscous flow mass conservation 流体微团: 跟着流体微团：$\frac{Dm}{Dt} = 0$ $ \frac{D}{Dt} (\rho V) = \rho \frac{DV} {Dt} + V \frac{D\rho }{Dt}= 0$ $=\rho v \nabla v + v \frac{D\rho}{Dt}$ $\frac{D V}{Dt} / V = \nabla \cdot V$ V (\rho \nabla \cdot V + \frac{\partial\rho}{\partial t} + V \cdot \nabla \rho) =0\frac{\partial \rho}{\partial t} + \nabla \cdot (\rho V)= 0monmentum Eq:\frac{\rho v V}{Dt} = body force + surface force\rho v \frac{DV}{Dt} = \rho V g + v V \cdot \tau\rho \frac{DV}{Dt} = \rho \vec{g} + \nabla \tau\frac{\partial \rho V}{\partial t} + V\cdot (\rho VV - \tau) = \rho g\vec{f}_{surface} = \int \int \tau \cdot n dt = \int \int \int \nabla \cdot \tau dv = \nabla \cdot \tau VEnergy Eqn: (流体微团)1st-laws of thermaodynamics: E = \rho \hat{V}(e + 0.5 V^2 - g \cdot r)$m= \rho \hat{V}= const$ \frac{DE}{Dt} = \frac{DQ}{Dt} + \frac{DW}{Dt} 热交换 对外做功 \frac{DQ}{Dt} = \int\int -q \cdot n dx = -\int \int \int - \nabla \cdot q dV = -\nabla \cdot q \hat{V}Assumption Fourier’s Law : $q = -R \nabla T$ (其中一个假设，可换成其他 不一定对) q \approx g \frac{DW}{Dt} = \int \int (\tau \cdot n)\cdot V dS = \int \int v \cdot (\tau \cdot n) ds = \int \int \int \nabla \cdot (V \cdot \tau)dV = \nabla\cdot (V\cdot \tau)\cdot V (力点乘速度等于功) \rho (\frac{De}{Dt} + \frac{D(\frac{1}{2} V^2)}{Dt} + \frac{D}{Dt} (-g \cdot r)) = \nabla \cdot (k \nabla T) + \nabla \cdot (V \cdot \tau)e : internal energy (therinal )for unit mass 粒子3个translation degree ， 粒子内部旋转振动有k个自由度。 each egreee of reedom shares the same amount of energy m: molecula mass e = \frac{1}{m} ( k + 3) \frac{1}{2}\hat{k} T$\hat{k}$ : : Boltzomann constant , T temperature $C_v$ specific heat at constant volume $C_p$, at constant pressure $r,R$ \delta Q= C_v dTde = \frac{1}{m} \frac{k+3}{2} \hat{k} dT = C_v dT = \frac{k + 3}{2} R dTC_v = \frac{k + 3}{2}R , \frac{k}{m} =R加多少热量保持压力不变： \delta Q = C_p dT = C_v dT + P dV = C_vdT + R dT$p = \rho R T , p = \frac{1}{V} RT, PV = RT$ C_p = C_v + R = \frac{k + 3 +2 }{2}R\gamma = \frac{C_p}{C_v} = \frac{k + 5}{k + 3} = 5/3 ,k =0; 7/5 = 1.4,k=2; isothermal, k= \infty;energy:\rho (\frac{De}{Dt} + \frac{D \frac{1}{2}V^2}{Dt}) = \nabla \cdot (V\cdot \tau) \text{流体加速运动} + \nabla\cdot (\hat{k} \nabla T) \text{热量}momentum:\rho \frac{DV}{Dt} = \nabla \cdot \tau\nabla \cdot (V \cdot \tau) = V \cdot (\nabla \cdot \tau) + \tau_{ij} \frac{\partial V_i}{\partial x_j}thermal energy eqn: \rho \frac{De}{Dt} = \nabla \cdot (\hat{k} \nabla T) + \tau_{ij} \frac{\partial u_i}{\partial x_j}\tau = -P \delta_{ij} + \sigma_{ij} P \nabla \cdot V = -\frac{P}{\rho} \frac{D\rho}{Dt} = \rho \frac{D}{Dt} \frac{p}{\rho} - \frac{D\rho}{Dt} \rho \frac{D}{Dt} (e + \frac{p}{\rho}) = \frac{DP}{Dt} + \nabla\cdot (\hat{k} \nabla T) + \sigma_{ij} \frac{\partial V_i}{\partial x_j} (heat)\geq 0\rho \frac{Dh}{Dt} = \frac{Dp}{Dt} + \nabla \cdot (\hat{k} \nabla T) + \Phitermodynamic identity: dh = C_p T + (1+ 1/\rho (\frac{\partial \rho}{\partial T})_p T \frac{dp}\rholow speed incompressible flow: \rho c_p \frac{DT}{Dt} = \nabla \cdot (\hat{k} \nabla T) \tau_{ij} = -P \delta_{ij} + \mu [ \frac{\partial V_i}{\partial x_j} + \frac{\partial V_j}{\partial x_i} -2/3 \nabla V ]+ \mu \frac{2k}{3(k+3)} \nabla V + \mu \frac{2k}{3(k+3)} \nabla V \approx T_{rot} -T_t各个方向的温度 $\approx T_{ij} - T_{eq}$ $\mu$ : dynamic viscosity coefficient$\hat{k}$::heat conduction coefficient \mu \approx \frac{1}{3}c l c: 声速, l: mean free path]]></content>
      <categories>
        <category>summmer school</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Markdown Note]]></title>
    <url>%2F2018%2FMarkdown-Note.html</url>
    <content type="text"><![CDATA[加粗倾斜 _jiacu heiti_ 倾斜加粗 delete line 分割线 简书 引用 引用 引用 引用 12345[![name](markdown-note/download.jpg &apos;百度&apos;)](http://www.baidu.com)![helloworld][first link][first link]: markdown-note/download.jpg helloworld baidu 文本结构 text 1 text 2 text 3 text 1 text 2 text 3 Tintin A reporter Has poofy orange hair Friends with the world’s most awesome dog Friends with the world’s most awesome dog Haddock A sea captain Has a fantastic beard Loves whiskey Possibly also scotch? 数学公式行间公式恒等式: cos^2(x) + sin^2(x) = 1x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}行内公式恒等式：$cos^2(x) + sin^2(x) = 1$,$x=\frac{-b \pm \sqrt{b^2-4ac}}{2a}$ 插入代码单行printf(&quot;helloworld&quot;); 多行插入C++ 代码： 1234printf("helloworld");printf("helloworld");printf("helloworld");printf("helloworld"); 插入Java 代码： 12345public class test &#123; public static void main(String[] args) &#123; System.out.println("helloworld"); &#125;&#125; 插入 Bash 代码: 1$ g++ -O3 test.c -lGl -lGLu -lglut -o test 表格 Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 dog bird cat foo foo foo bar bar bar baz baz baz 质能方程 download.jpg 1printf("helloworld"); 插入视频upload video : https://openload.co/ have sex ad https://mega.nz/fm/xo9RgIba 下载源码 [Download Markdown-Note.md](https://drive.google.com/file/d/1A7oz33irmY_ZpKNLXKTGOyv0askhgral/view?usp=sharing) A=$\begin{bmatrix}4 &amp; 0 &amp; 0\\\ 0 &amp; -6 &amp; 0 \\\ 0&amp; 0&amp;2 \end{bmatrix}$ 换行三个slash $cond(A) = |A|_1 \cdot |A^{-1}|_1 = 6 * 0.5 = 3$ $cond(A) = |A|_ {\infty} \cdot |A^{-1}|_ {\infty} = 6 * 0.5 = 3$ 空格在 infty前 花括号 {} \\{ \\} math formula error 行内公式有*， 或重打一遍。]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>图片</tag>
        <tag>代码</tag>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
